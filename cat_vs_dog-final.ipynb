{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 机器学习纳米学位\n",
    "猫狗大战毕业项目   \n",
    "张斌   \n",
    "2019年3月6日   \n",
    "\n",
    "## 项目说明\n",
    "\n",
    "本项目是优达学城的一个毕业项目。项目要求使用深度学习方法识别一张图片是猫还是狗\n",
    "\n",
    "- 输入：一张彩色图片\n",
    "- 输出：是猫还是狗\n",
    "\n",
    "## 实验环境\n",
    "项目使用Anaconda搭建环境。使用environment目录下的yml进行环境安装。   \n",
    "\n",
    "$ conda env create -f environmert/environmert.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据探索及预处理\n",
    "\n",
    "从 [Dogs vs. Cats Redux: Kernels Edition](https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data) 下载并解压训练数据到`data`目录。   \n",
    "数据集由训练数据和测试数据组成，训练数据包含猫和狗各12500张图片，测试数据包含12500张猫和狗的图片。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "# 提供文件和文件集合的高级操作，复制、删除等\n",
    "import shutil\n",
    "from PIL import Image\n",
    "# 导入计数\n",
    "from collections import Counter\n",
    "# 文件操作模块\n",
    "from glob import glob\n",
    "from sklearn.utils import shuffle\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input as preprocess_input_ResNet50\n",
    "from keras.applications.xception import Xception, preprocess_input as preprocess_input_Xception\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input as preprocess_input_InceptionV3\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input as preprocess_input_InceptionResNetV2\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import ModelCheckpoint \n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Lambda, Dense, Dropout, Flatten\n",
    "from keras.utils import np_utils\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载图片数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train 中的数据\n",
    "train_files = glob(\"data/train/*\")\n",
    "train_files = np.array(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test 中的数据\n",
    "test_files = glob(\"data/test/*\")\n",
    "test_files = np.array(test_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 剔除异常值   \n",
    "对`train`中所有的图片进行图像直方图分析，对图片中包含的色彩与图片的像素的比值进行分析，此次利用箱型图原理，显示一组数据分散情况，箱形图为我们提供了识别异常值的一个标准：异常值被定义为小于Q1－1.5IQR或大于Q3+1.5IQR的值，从而筛选出异常值，并剔除。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 利用直方图，计算图片中的色彩与图片像素的比值函数\n",
    "def calhistogram(file):\n",
    "    # 打开图片\n",
    "    img = Image.open(file)\n",
    "    # 直方图\n",
    "    his = img.histogram()\n",
    "    # 计算色彩的数量\n",
    "    count = Counter(his)\n",
    "    # 计算色彩数量和图片像素的比值\n",
    "    return float(len(count))/len(his)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 建立所有图片色彩和图片像素的比值的list\n",
    "color_pixel_ratio_list = []\n",
    "for train_file in train_files:\n",
    "    color_pixel_ratio_list.append(calhistogram(train_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 创建图片色彩和图片像素的比值和图片地址的dict\n",
    "color_pixel_dict = dict(zip(color_pixel_ratio_list,train_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "识别异常值的一个标准：异常值被定义为小于Q1－1.5IQR或大于Q3+1.5IQR的值,计算出项目中的两个点。    \n",
    "利用`np.percentile`方法，返回第q个百分位数，两个异常值判断点分别如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一四分位数\n",
    "Q1 = np.percentile(color_pixel_ratio_list, [25])\n",
    "# 第三四分位数\n",
    "Q3 = np.percentile(color_pixel_ratio_list, [75])\n",
    "# 四分位距IQR\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# 异常值1\n",
    "abnormal_1 = Q1 - 1.5 * IQR\n",
    "# 异常值2\n",
    "abnormal_2 = Q3 + 1.5 * IQR\n",
    "\n",
    "print(abnormal_1, abnormal_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 筛选出异常的图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 异常图片list\n",
    "abnormal_pic_list = []\n",
    "for key, value in color_pixel_dict.items():\n",
    "    # 判断小于异常值\n",
    "    if key < abnormal_1:\n",
    "        # 加入异常pic列表中\n",
    "        abnormal_pic_list.append(value)\n",
    "        # 打开异常pic，并展示\n",
    "        \n",
    "    # 判断大于异常值\n",
    "    if key > abnormal_2:\n",
    "        # 加入异常pic列表中\n",
    "        abnormal_pic_list.append(value)\n",
    "        \n",
    "# 输出所有异常picture        \n",
    "print('异常图片的数量为：' + str(len(abnormal_pic_list)) + '张')\n",
    "# 显示异常图片\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "for i, val in enumerate(abnormal_pic_list[50:60]):\n",
    "    ax = fig.add_subplot(1, 10, i + 1, xticks=[], yticks=[])\n",
    "    abnormal_img = Image.open(val) \n",
    "    # 异常图片名称,待添加\n",
    "    ax.imshow(abnormal_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立新建文件夹函数，将异常的图片剪切到新的文件夹中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 新建文件夹，如有重名删除原文件夹\n",
    "def create_folder(dirname):\n",
    "    # 判断dirname文件是否存在\n",
    "    if os.path.exists(dirname):\n",
    "        # 表示递归删除文件夹下的所有子文件夹和子文件\n",
    "        shutil.rmtree(dirname)\n",
    "    # 创建目录\n",
    "    os.mkdir(dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 常见异常图片文件夹\n",
    "create_folder('data/abnormal_pic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 移动异常图片到'abnormal_pic'文件夹\n",
    "# 记录移动pic的数量rmove_pic_num\n",
    "rmove_pic_num = 0\n",
    "for pic_file in abnormal_pic_list:\n",
    "    shutil.move( pic_file, 'data/abnormal_pic/' + pic_file[11:-4])\n",
    "    rmove_pic_num = rmove_pic_num + 1\n",
    "print('共移动图片' + str(rmove_pic_num) + '张。')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立训练和验证集\n",
    "`train`中的文件名为`类型.序号.jpg`，例如`cat.0.jpg`，将`train`中的图片随机分为训练集和验证集，根据类型进行标记,为下一步监督学习做准备。生成以下变量   \n",
    "- `train_files_rem`, `valid_files_rem`, - 包含图像的文件路径的numpy数组\n",
    "- `train_targets`, `valid_targets`, - 包含独热编码分类标签的numpy数组\n",
    "- `pic_type` - 由字符串构成的与标签相对应的狗的种类\n",
    "\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 将pic_files中的图片随机分配到train_files, valid_files，比例是4:1\n",
    "# 更新图片后的train_files\n",
    "train_files = glob(\"data/train/*\")\n",
    "train_files = np.array(train_files)\n",
    "# 打印数据集的数据量\n",
    "print('There are %d total images.' % len(train_files))\n",
    "index_valid = np.random.choice(train_files.shape[0], int(len(train_files)*0.2), replace=False)\n",
    "index_train_files = np.arange(train_files.shape[0])\n",
    "index_train = np.delete(index_train_files,index_valid)\n",
    "\n",
    "#训练集和验证集的数据\n",
    "train_files_rem = train_files[index_train]\n",
    "print('There are %d train images.' % len(train_files_rem))\n",
    "valid_files_rem = train_files[index_valid]\n",
    "print('There are %d valid images.' % len(valid_files_rem))\n",
    "# 输出测试集的数量\n",
    "print('There are %d test images.' % len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  生成标记函数\n",
    "def generate_targets(data):\n",
    "    result = []\n",
    "    for value in data:\n",
    "        if 'cat' in str(value):\n",
    "            result.append(0)\n",
    "        elif 'dog' in str(value):\n",
    "            result.append(1)\n",
    "        else:\n",
    "            print('err')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 将训练集合验证集的数据中根据类型进行标记，分为1和0，分别对应cat和dog两类，并存入train_targets, valid_targets中。\n",
    "train_targets = generate_targets(train_files_rem)\n",
    "valid_targets = generate_targets(valid_files_rem)\n",
    "train_targets = np_utils.to_categorical(np.array(train_targets), 2)\n",
    "valid_targets = np_utils.to_categorical(np.array(valid_targets), 2)\n",
    "pic_type = ['cat', 'dog']\n",
    "print('There are %d train targets.' % len(train_targets))\n",
    "print('There are %d valid targets.' % len(valid_targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理数据\n",
    "批量加载图片，并将图片转为数字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 将图片转为数字\n",
    "def path_to_tensor(img_path, size):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=size)\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "# 批量转换\n",
    "def paths_to_tensor(img_paths, size):\n",
    "    list_of_tensors = [path_to_tensor(img_path, size) for img_path in img_paths]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 将train, test, and validation datasets 从img转为数据组\n",
    "train_mode = paths_to_tensor(train_files_rem, (299, 299))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_mode = paths_to_tensor(valid_files_rem, (299, 299))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_mode = paths_to_tensor(test_files, (299, 299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 展示6张图片\n",
    "fig = plt.figure(figsize=(20,5))\n",
    "for i in range(6):\n",
    "    ax = fig.add_subplot(1, 6, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(train_mode[i]/256))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用迁移学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用预训练的基于模型作为固定的图像特征提取器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "封装图像特征提取器到函数内"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Image_feature_extractor(input_model, image_size, train_mode, valid_mode, test_mode, lambda_func=None):\n",
    "    # 建立预训练的模型\n",
    "    print('建立模型')\n",
    "    width = image_size[0]\n",
    "    height = image_size[1]\n",
    "    input_tensor = Input((height, width, 3))\n",
    "    x = input_tensor\n",
    "    if lambda_func:\n",
    "        x = Lambda(lambda_func)(x)\n",
    "    base_model = input_model(input_tensor=x, weights='imagenet', include_top=False)\n",
    "    # 创建新的model\n",
    "    model = Model(base_model.input, GlobalAveragePooling2D()(base_model.output))\n",
    "    print('完成')\n",
    "    # 归一化数据等预处理数据\n",
    "#     train_mode_pre = preprocess_input(train_mode)\n",
    "#     valid_mode_pre = preprocess_input(valid_mode)\n",
    "#     test_mode_pre = preprocess_input(test_mode)   \n",
    "    # 提取特征向量\n",
    "    train = model.predict(train_mode)\n",
    "    print('实例，查看提取特征向量情况' + str(train[0]))\n",
    "    print('完成train预处理')\n",
    "    valid = model.predict(valid_mode)\n",
    "    print('完成train预处理')\n",
    "    test = model.predict(test_mode)\n",
    "    print('完成test预处理')\n",
    "    train_target = train_targets\n",
    "    valid_target = valid_targets\n",
    "    #为了后续使用test_name,所以此次将test_files出入npz文件中\n",
    "    test_files_name = test_files\n",
    "\n",
    "    # 概览模型\n",
    "#     model.summary()\n",
    "\n",
    "    # print resule\n",
    "    print('There are %d training images.' % len(train))\n",
    "    print('There are %d validation images.' % len(valid))\n",
    "    print('There are %d test images.'% len(test))\n",
    "    \n",
    "    # 将提取的特征向量存入文件\n",
    "    np.savez(\"data/pre_data/cat_dog_%s.npz\"%input_model.__name__, train = train, valid = valid, test = test, train_target = train_target, valid_target = valid_target, test_files_name = test_files_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 基于ResNet50 提取特征向量\n",
    "Image_feature_extractor(ResNet50, (299, 299), train_mode, valid_mode, test_mode, preprocess_input_ResNet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 基于InceptionV3提取特征向量\n",
    "Image_feature_extractor(InceptionV3, (299, 299), train_mode, valid_mode, test_mode,  preprocess_input_InceptionV3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 基于InceptionResNetV2 提取特征向量\n",
    "Image_feature_extractor(InceptionResNetV2, (299, 299), train_mode, valid_mode, test_mode, preprocess_input_InceptionResNetV2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 基于Xception 提取特征向量\n",
    "Image_feature_extractor(Xception, (299, 299), train_mode, valid_mode, test_mode,  preprocess_input_Xception)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成训练数据\n",
    "根据特征向量提取器预处理的数据，形成训练、验证和测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "glob('data/pre_data/*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以下部分需要执行5次并比较，5次分别是单独使用InceptionResNetV2，InceptionV3，ResNet50，Xception特征向量，和组合四个特征向量拼接和组合三个特征向量拼接作为输入，最近对预测结果进行比较，选择最优模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#加载预处理的数据进行拼接，建立训练、验证、测试数据集\n",
    "X_train = []\n",
    "X_valid = []\n",
    "X_test = []\n",
    "\n",
    "y_train = []\n",
    "y_valid = []\n",
    "\n",
    "#加载预处理的数据\n",
    "for filename in ['data/pre_data/cat_dog_Xception.npz']:\n",
    "    mid = np.load(filename)\n",
    "    X_train.append(mid['train'])\n",
    "    X_valid.append(mid['valid'])\n",
    "    X_test.append(mid['test'])\n",
    "    test_files_name = mid['test_files_name']\n",
    "    \n",
    "    y_train = mid['train_target']\n",
    "    y_valid = mid['valid_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 按照行的方向拼接数据\n",
    "X_train = np.concatenate(X_train, axis=1)\n",
    "X_test = np.concatenate(X_test, axis=1)\n",
    "X_valid = np.concatenate(X_valid, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 建立CNN模型\n",
    "model = Sequential()\n",
    "model.add(Dense(X_train.shape[1], input_shape=X_train.shape[1:]))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(int(X_train.shape[1]/2), activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "# 模型概括\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将训练集随机打乱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#训练模型\n",
    "epochs = 10\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='data/model.weights.best.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model_history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=epochs, batch_size=128, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载最优模型\n",
    "model.load_weights('data/model.weights.best.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测test中的结果\n",
    "test_targets = model.predict(X_test, verbose=1)\n",
    "test_targets = test_targets.clip(min=0.005, max=0.995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 创建label\n",
    "# label的值越接近1表示dog，越接近0表示cat\n",
    "label = []\n",
    "for test_target in test_targets:\n",
    "    if np.argmax(test_target) == 0:\n",
    "        label.append(1 - test_target[0])\n",
    "    elif np.argmax(test_target) == 1:\n",
    "        label.append(test_target[1])\n",
    "    else:\n",
    "        print('err')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#创建ID\n",
    "num = []\n",
    "for test_name in test_files_name:\n",
    "    num.append(re.sub(\"\\D\", \"\",test_name[10:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 按照要求生成sample_submission.csv文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#字典中的key值即为csv中列名\n",
    "sample_submission = pd.DataFrame({'id':num,'label':label})\n",
    "# 将'id'转为int\n",
    "sample_submission['id'] = sample_submission['id'].astype(int)\n",
    "# 排序\n",
    "sample_submission = sample_submission.sort_values(by='id')\n",
    "#将DataFrame存储为csv,index表示是否显示行名，default=True\n",
    "sample_submission.to_csv('data/submission.csv',index=False,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 显示10条数据\n",
    "sample_submission.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# 可视化\n",
    "def plot_training(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    epochs = range(len(acc))\n",
    "    plt.plot(epochs, acc, 'b')\n",
    "    plt.plot(epochs, val_acc, 'r')\n",
    "    plt.legend([\"binary_accuracy\", \"val_binary_accuracy\"], loc='best')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.figure()\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']   \n",
    "    plt.plot(epochs, loss, 'b')\n",
    "    plt.plot(epochs, val_loss, 'r')\n",
    "    plt.legend([\"loss\", \"val_loss\"], loc='best')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.show()\n",
    "\n",
    "# 训练的acc_loss图\n",
    "plot_training(model_history)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
